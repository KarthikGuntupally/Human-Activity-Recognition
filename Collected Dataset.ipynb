{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6uhvePx52zS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv('/content/sd.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CvqbssYL6eaN",
        "outputId": "680496bd-3b15-4931-d17d-1d951016d234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Acc x axis  Acc y axis  Acc z axis  Gyr x axis  Gyr y axis  Gyr z axis  \\\n",
              "0   -9.844670   -1.053141    1.637289    0.070706   -0.199747   -0.106746   \n",
              "1   -9.471390   -1.100998    1.857429    0.076814   -0.362232   -0.103080   \n",
              "2   -9.380463   -1.208675    1.606182    0.069484   -0.287709   -0.155613   \n",
              "3   -9.892527   -0.234796    2.091925    0.087809   -0.171648   -0.297330   \n",
              "4   -9.892527   -0.447757    2.312065    0.124460   -0.203412   -0.111632   \n",
              "\n",
              "   Label  \n",
              "0      1  \n",
              "1      1  \n",
              "2      1  \n",
              "3      1  \n",
              "4      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ade6c1a-e567-4055-9d5d-1bc9398ed37e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Acc x axis</th>\n",
              "      <th>Acc y axis</th>\n",
              "      <th>Acc z axis</th>\n",
              "      <th>Gyr x axis</th>\n",
              "      <th>Gyr y axis</th>\n",
              "      <th>Gyr z axis</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-9.844670</td>\n",
              "      <td>-1.053141</td>\n",
              "      <td>1.637289</td>\n",
              "      <td>0.070706</td>\n",
              "      <td>-0.199747</td>\n",
              "      <td>-0.106746</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-9.471390</td>\n",
              "      <td>-1.100998</td>\n",
              "      <td>1.857429</td>\n",
              "      <td>0.076814</td>\n",
              "      <td>-0.362232</td>\n",
              "      <td>-0.103080</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-9.380463</td>\n",
              "      <td>-1.208675</td>\n",
              "      <td>1.606182</td>\n",
              "      <td>0.069484</td>\n",
              "      <td>-0.287709</td>\n",
              "      <td>-0.155613</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-9.892527</td>\n",
              "      <td>-0.234796</td>\n",
              "      <td>2.091925</td>\n",
              "      <td>0.087809</td>\n",
              "      <td>-0.171648</td>\n",
              "      <td>-0.297330</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-9.892527</td>\n",
              "      <td>-0.447757</td>\n",
              "      <td>2.312065</td>\n",
              "      <td>0.124460</td>\n",
              "      <td>-0.203412</td>\n",
              "      <td>-0.111632</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ade6c1a-e567-4055-9d5d-1bc9398ed37e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ade6c1a-e567-4055-9d5d-1bc9398ed37e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ade6c1a-e567-4055-9d5d-1bc9398ed37e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-80a13594-4090-4eb8-a832-b1b6f4e73673\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80a13594-4090-4eb8-a832-b1b6f4e73673')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-80a13594-4090-4eb8-a832-b1b6f4e73673 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 12000,\n  \"fields\": [\n    {\n      \"column\": \"Acc x axis\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.275712902111882,\n        \"min\": -29.61177826,\n        \"max\": 9.970293999,\n        \"num_unique_values\": 3637,\n        \"samples\": [\n          -18.5976162,\n          -8.363512993,\n          -9.9140625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acc y axis\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.0454281299576245,\n        \"min\": -11.54088306,\n        \"max\": 10.33190918,\n        \"num_unique_values\": 2928,\n        \"samples\": [\n          -2.622832775,\n          0.241375983,\n          2.028814554\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acc z axis\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6403921113405884,\n        \"min\": -5.660820007,\n        \"max\": 20.29412651,\n        \"num_unique_values\": 2826,\n        \"samples\": [\n          3.403192043,\n          0.096311115,\n          4.903491974\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gyr x axis\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4454071600770835,\n        \"min\": -3.705246687,\n        \"max\": 3.283456802,\n        \"num_unique_values\": 4467,\n        \"samples\": [\n          -0.048562355,\n          0.116824538,\n          -0.390331388\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gyr y axis\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33783498515337684,\n        \"min\": -2.692920208,\n        \"max\": 2.090319395,\n        \"num_unique_values\": 3534,\n        \"samples\": [\n          -0.029015245,\n          -1.064706802,\n          0.247851282\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gyr z axis\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3345689226466898,\n        \"min\": -2.295411348,\n        \"max\": 3.1356318,\n        \"num_unique_values\": 3962,\n        \"samples\": [\n          0.39903596,\n          0.022448637,\n          -0.405755281\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-ouV8736i3P",
        "outputId": "e906e346-9865-4f1c-f8db-ca437af6046e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Acc x axis', 'Acc y axis', 'Acc z axis', 'Gyr x axis', 'Gyr y axis',\n",
              "       'Gyr z axis', 'Label'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Defining the feature columns and the target variable\n",
        "X = data[['Acc x axis', 'Acc y axis', 'Acc z axis', 'Gyr x axis', 'Gyr y axis', 'Gyr z axis']]\n",
        "y = data['Label']\n",
        "\n",
        "# Splitting the data into training and testing sets with a 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initializing and training the logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the labels for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculating the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9A3T7nQ7MnK",
        "outputId": "30178ff5-24d4-421d-be1b-f398c5ec5e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5063888888888889"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Defining the feature columns and the target variable\n",
        "X = data[['Acc x axis', 'Acc y axis', 'Acc z axis', 'Gyr x axis', 'Gyr y axis', 'Gyr z axis']]\n",
        "y = data['Label']\n",
        "\n",
        "# Splitting the data into training and testing sets with a 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initializing and training the Decision Tree classifier\n",
        "decision_tree_model = DecisionTreeClassifier()\n",
        "decision_tree_model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the labels for the test set\n",
        "y_pred = decision_tree_model.predict(X_test)\n",
        "\n",
        "# Calculating the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f'Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjFP7ScJ7feq",
        "outputId": "5133ff1f-e8ef-4b77-b8ac-051e0765c41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7480555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Defining the feature columns and the target variable\n",
        "X = data[['Acc x axis', 'Acc y axis', 'Acc z axis', 'Gyr x axis', 'Gyr y axis', 'Gyr z axis']]\n",
        "y = data['Label']\n",
        "\n",
        "# Splitting the data into training and testing sets with a 70:30 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initializing and training the Random Forest classifier\n",
        "random_forest_model = RandomForestClassifier(n_estimators=100)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the labels for the test set\n",
        "y_pred = random_forest_model.predict(X_test)\n",
        "\n",
        "# Calculating the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy\n",
        "print(f'Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RboSY4Z7va0",
        "outputId": "60ff4e5e-a224-4b41-dfd5-d7b56fe3f519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8097222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'Acc x axis', 'Acc y axis', 'Acc z axis', 'Gyr x axis', 'Gyr y axis', 'Gyr z axis' are your features\n",
        "X = data[['Acc x axis', 'Acc y axis', 'Acc z axis', 'Gyr x axis', 'Gyr y axis', 'Gyr z axis']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# One-hot encode your labels if they're not already\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reshaping for 1D CNN\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# Define the 1D CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and save the history\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=2)\n",
        "\n",
        "# Accessing the history to retrieve the final accuracy values\n",
        "history_dict = history.history\n",
        "final_train_accuracy = history_dict['accuracy'][-1]  # Last value in accuracy list\n",
        "final_val_accuracy = history_dict['val_accuracy'][-1]  # Last value in val_accuracy list\n",
        "\n",
        "# Print the final accuracy values\n",
        "print(f\"Final Training Accuracy: {final_train_accuracy*100:.2f}%\")\n",
        "print(f\"Final Validation Accuracy: {final_val_accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0986aCE873G_",
        "outputId": "e35e3386-a9a7-4a12-a2ce-4ef42014875b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "263/263 - 2s - loss: 1.1080 - accuracy: 0.5629 - val_loss: 0.7585 - val_accuracy: 0.6597 - 2s/epoch - 8ms/step\n",
            "Epoch 2/10\n",
            "263/263 - 1s - loss: 0.6885 - accuracy: 0.6925 - val_loss: 0.6511 - val_accuracy: 0.6992 - 1s/epoch - 4ms/step\n",
            "Epoch 3/10\n",
            "263/263 - 1s - loss: 0.6192 - accuracy: 0.7099 - val_loss: 0.6224 - val_accuracy: 0.7025 - 1s/epoch - 5ms/step\n",
            "Epoch 4/10\n",
            "263/263 - 1s - loss: 0.5898 - accuracy: 0.7231 - val_loss: 0.5865 - val_accuracy: 0.7319 - 1s/epoch - 4ms/step\n",
            "Epoch 5/10\n",
            "263/263 - 1s - loss: 0.5701 - accuracy: 0.7396 - val_loss: 0.5869 - val_accuracy: 0.7211 - 740ms/epoch - 3ms/step\n",
            "Epoch 6/10\n",
            "263/263 - 1s - loss: 0.5604 - accuracy: 0.7410 - val_loss: 0.5681 - val_accuracy: 0.7350 - 732ms/epoch - 3ms/step\n",
            "Epoch 7/10\n",
            "263/263 - 1s - loss: 0.5521 - accuracy: 0.7482 - val_loss: 0.5610 - val_accuracy: 0.7450 - 854ms/epoch - 3ms/step\n",
            "Epoch 8/10\n",
            "263/263 - 1s - loss: 0.5401 - accuracy: 0.7568 - val_loss: 0.5630 - val_accuracy: 0.7436 - 850ms/epoch - 3ms/step\n",
            "Epoch 9/10\n",
            "263/263 - 1s - loss: 0.5357 - accuracy: 0.7614 - val_loss: 0.5450 - val_accuracy: 0.7519 - 733ms/epoch - 3ms/step\n",
            "Epoch 10/10\n",
            "263/263 - 1s - loss: 0.5317 - accuracy: 0.7590 - val_loss: 0.5472 - val_accuracy: 0.7547 - 768ms/epoch - 3ms/step\n",
            "Final Training Accuracy: 75.90%\n",
            "Final Validation Accuracy: 75.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv1D, Flatten, MaxPooling1D, concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_custom_model(input_shape, num_classes):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # Parallel Convolutional Layers with padding='same' to maintain input length\n",
        "    conv1 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "    conv1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "\n",
        "    conv2 = Conv1D(filters=64, kernel_size=3, activation='elu', padding='same')(input_layer)\n",
        "    conv2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "\n",
        "    conv3 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "    conv3 = MaxPooling1D(pool_size=2)(conv3)\n",
        "\n",
        "    # Merging Layers\n",
        "    merged = concatenate([conv1, conv2, conv3])\n",
        "\n",
        "    # Additional Convolutional Layers applied sequentially after merge\n",
        "    conv4 = Conv1D(filters=16, kernel_size=5, activation='relu', padding='same')(merged)\n",
        "    conv5 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(conv4)\n",
        "    conv6 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    # Flatten and Dense Layer\n",
        "    flatten = Flatten()(conv6)\n",
        "    dense = Dense(256, activation='relu')(flatten)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(dense)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Assuming data loading and preprocessing:\n",
        "# Load your data here, e.g., a CSV file containing feature columns and labels\n",
        "X = data[['Acc x axis', 'Acc y axis', 'Acc z axis', 'Gyr x axis', 'Gyr y axis', 'Gyr z axis']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# One-hot encode your labels\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for 1D convolution\n",
        "X_scaled = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = create_custom_model((X_train.shape[1], 1), y_train.shape[1])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {evaluation[0]}, Test Accuracy: {evaluation[1]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-w-oLc0JHYA",
        "outputId": "4b9080aa-4298-4cdf-e1b5-dd4b5107de6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 6, 1)]               0         []                            \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)          (None, 6, 32)                128       ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)          (None, 6, 64)                256       ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)          (None, 6, 32)                128       ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling1d_11 (MaxPooli  (None, 3, 32)                0         ['conv1d_14[0][0]']           \n",
            " ng1D)                                                                                            \n",
            "                                                                                                  \n",
            " max_pooling1d_12 (MaxPooli  (None, 3, 64)                0         ['conv1d_15[0][0]']           \n",
            " ng1D)                                                                                            \n",
            "                                                                                                  \n",
            " max_pooling1d_13 (MaxPooli  (None, 3, 32)                0         ['conv1d_16[0][0]']           \n",
            " ng1D)                                                                                            \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 3, 128)               0         ['max_pooling1d_11[0][0]',    \n",
            " )                                                                   'max_pooling1d_12[0][0]',    \n",
            "                                                                     'max_pooling1d_13[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)          (None, 3, 16)                10256     ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)          (None, 3, 64)                5184      ['conv1d_17[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)          (None, 3, 32)                6176      ['conv1d_18[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)         (None, 96)                   0         ['conv1d_19[0][0]']           \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 256)                  24832     ['flatten_4[0][0]']           \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 7)                    1799      ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 48759 (190.46 KB)\n",
            "Trainable params: 48759 (190.46 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "300/300 [==============================] - 6s 10ms/step - loss: 0.7592 - accuracy: 0.6604 - val_loss: 0.5867 - val_accuracy: 0.7042\n",
            "Epoch 2/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.5501 - accuracy: 0.7395 - val_loss: 0.5770 - val_accuracy: 0.7163\n",
            "Epoch 3/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.5249 - accuracy: 0.7589 - val_loss: 0.5146 - val_accuracy: 0.7646\n",
            "Epoch 4/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.5066 - accuracy: 0.7733 - val_loss: 0.5098 - val_accuracy: 0.7625\n",
            "Epoch 5/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.4973 - accuracy: 0.7733 - val_loss: 0.5109 - val_accuracy: 0.7671\n",
            "Epoch 6/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.4867 - accuracy: 0.7783 - val_loss: 0.5073 - val_accuracy: 0.7671\n",
            "Epoch 7/30\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.4713 - accuracy: 0.7862 - val_loss: 0.4951 - val_accuracy: 0.7704\n",
            "Epoch 8/30\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 0.4658 - accuracy: 0.7916 - val_loss: 0.4788 - val_accuracy: 0.7867\n",
            "Epoch 9/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.4608 - accuracy: 0.7952 - val_loss: 0.5014 - val_accuracy: 0.7788\n",
            "Epoch 10/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.4513 - accuracy: 0.7962 - val_loss: 0.4733 - val_accuracy: 0.7833\n",
            "Epoch 11/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.4419 - accuracy: 0.8058 - val_loss: 0.4818 - val_accuracy: 0.7825\n",
            "Epoch 12/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.4357 - accuracy: 0.8062 - val_loss: 0.4701 - val_accuracy: 0.7858\n",
            "Epoch 13/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.4260 - accuracy: 0.8111 - val_loss: 0.4815 - val_accuracy: 0.7817\n",
            "Epoch 14/30\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.4258 - accuracy: 0.8123 - val_loss: 0.4730 - val_accuracy: 0.7846\n",
            "Epoch 15/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.4147 - accuracy: 0.8161 - val_loss: 0.4644 - val_accuracy: 0.7958\n",
            "Epoch 16/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.4017 - accuracy: 0.8261 - val_loss: 0.4831 - val_accuracy: 0.7821\n",
            "Epoch 17/30\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.4011 - accuracy: 0.8202 - val_loss: 0.4721 - val_accuracy: 0.8012\n",
            "Epoch 18/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.3889 - accuracy: 0.8280 - val_loss: 0.4715 - val_accuracy: 0.7971\n",
            "Epoch 19/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.3821 - accuracy: 0.8320 - val_loss: 0.4860 - val_accuracy: 0.7987\n",
            "Epoch 20/30\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.3815 - accuracy: 0.8352 - val_loss: 0.4846 - val_accuracy: 0.7921\n",
            "Epoch 21/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.3750 - accuracy: 0.8376 - val_loss: 0.4818 - val_accuracy: 0.7879\n",
            "Epoch 22/30\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.3621 - accuracy: 0.8426 - val_loss: 0.4920 - val_accuracy: 0.7925\n",
            "Epoch 23/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.3606 - accuracy: 0.8473 - val_loss: 0.4883 - val_accuracy: 0.7879\n",
            "Epoch 24/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.3535 - accuracy: 0.8476 - val_loss: 0.4951 - val_accuracy: 0.8004\n",
            "Epoch 25/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.3419 - accuracy: 0.8491 - val_loss: 0.4837 - val_accuracy: 0.7933\n",
            "Epoch 26/30\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 0.3311 - accuracy: 0.8596 - val_loss: 0.4849 - val_accuracy: 0.8008\n",
            "Epoch 27/30\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.3263 - accuracy: 0.8604 - val_loss: 0.5138 - val_accuracy: 0.7925\n",
            "Epoch 28/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.3208 - accuracy: 0.8633 - val_loss: 0.5128 - val_accuracy: 0.7892\n",
            "Epoch 29/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.3172 - accuracy: 0.8659 - val_loss: 0.5026 - val_accuracy: 0.8021\n",
            "Epoch 30/30\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.3087 - accuracy: 0.8695 - val_loss: 0.5466 - val_accuracy: 0.7908\n",
            "75/75 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7908\n",
            "Test Loss: 0.5465750098228455, Test Accuracy: 0.7908333539962769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv1D, Flatten, MaxPooling1D, concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_custom_model(input_shape, num_classes):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # Parallel Convolutional Layers with padding='same' to maintain input length\n",
        "    conv1 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "    conv1 = MaxPooling1D(pool_size=2)(conv1)\n",
        "\n",
        "    conv2 = Conv1D(filters=64, kernel_size=3, activation='elu', padding='same')(input_layer)\n",
        "    conv2 = MaxPooling1D(pool_size=2)(conv2)\n",
        "\n",
        "    conv3 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
        "    conv3 = MaxPooling1D(pool_size=2)(conv3)\n",
        "\n",
        "    # Merging Layers\n",
        "    merged = concatenate([conv1, conv2, conv3])\n",
        "\n",
        "    # Additional Convolutional Layers applied sequentially after merge\n",
        "    conv4 = Conv1D(filters=16, kernel_size=5, activation='relu', padding='same')(merged)\n",
        "    conv4 = MaxPooling1D(pool_size=2)(conv4)  # Adding pooling after conv4\n",
        "\n",
        "    conv5 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(conv4)\n",
        "    conv5 = MaxPooling1D(pool_size=2)(conv5)  # Adding pooling after conv5\n",
        "\n",
        "    conv6 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(conv5)\n",
        "    conv6 = MaxPooling1D(pool_size=2)(conv6)  # Adding pooling after conv6\n",
        "\n",
        "    # Flatten and Dense Layer\n",
        "    flatten = Flatten()(conv6)\n",
        "    dense = Dense(256, activation='relu')(flatten)\n",
        "    output_layer = Dense(num_classes, activation='softmax')(dense)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Load your data here\n",
        "# data = pd.read_csv('path_to_your_data.csv')\n",
        "# Assuming data and labels are already defined\n",
        "\n",
        "X = data[['Acc x axis', 'Acc y axis', 'Acc z axis', 'Gyr x axis', 'Gyr y axis', 'Gyr z axis']].values\n",
        "y = data['Label'].values\n",
        "\n",
        "# One-hot encode your labels\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data for 1D convolution\n",
        "X_scaled = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = create_custom_model((X_train.shape[1], 1), y_train.shape[1])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {evaluation[0]}, Test Accuracy: {evaluation[1]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "VotGYEZYKtFq",
        "outputId": "4954b784-8ed1-4d41-8010-3fb6074ed229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"max_pooling1d_10\" (type MaxPooling1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling1d_10/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d_10/ExpandDims)' with input shapes: [?,1,1,64].\n\nCall arguments received by layer \"max_pooling1d_10\" (type MaxPooling1D):\n  â€¢ inputs=tf.Tensor(shape=(None, 1, 64), dtype=float32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5fac7093ea2e>\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Define the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_custom_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Model summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-5fac7093ea2e>\u001b[0m in \u001b[0;36mcreate_custom_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mconv5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mconv5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adding pooling after conv5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mconv6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   6640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6641\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6642\u001b[0;31m         x = tf.compat.v1.nn.max_pool(\n\u001b[0m\u001b[1;32m   6643\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_data_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6644\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling1d_10\" (type MaxPooling1D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling1d_10/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 1, 1], padding=\"VALID\", strides=[1, 2, 1, 1]](max_pooling1d_10/ExpandDims)' with input shapes: [?,1,1,64].\n\nCall arguments received by layer \"max_pooling1d_10\" (type MaxPooling1D):\n  â€¢ inputs=tf.Tensor(shape=(None, 1, 64), dtype=float32)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "# Prepare the dataset\n",
        "X = data[['Acc x axis', 'Acc y axis', 'Acc z axis', 'Gyr x axis', 'Gyr y axis', 'Gyr z axis']].values\n",
        "y = data['Label'].values\n",
        "y = to_categorical(y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# Hyperparameters\n",
        "filter_options = [32, 64, 128]\n",
        "kernel_sizes = [3, 5, 7]\n",
        "pool_sizes = [2, 3, 5]\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Function to train model\n",
        "def train_1D_CNN(X_train, y_train, X_test, y_test, filters, kernel_size, pool_size, learning_rate):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Calculate the size after convolution but before pooling\n",
        "    conv_size = X_train.shape[1] - kernel_size + 1\n",
        "\n",
        "    # Skip configurations where pooling is not possible\n",
        "    if conv_size <= pool_size:\n",
        "        return None, None\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "    model.add(MaxPooling1D(pool_size=pool_size))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=0)\n",
        "\n",
        "    runtime = time.time() - start_time\n",
        "    final_val_accuracy = history.history['val_accuracy'][-1]\n",
        "\n",
        "    return final_val_accuracy, runtime\n",
        "\n",
        "# Iterate over combinations and print results\n",
        "for filters in filter_options:\n",
        "    for kernel_size in kernel_sizes:\n",
        "        for pool_size in pool_sizes:\n",
        "            val_accuracy, runtime = train_1D_CNN(X_train, y_train, X_test, y_test,\n",
        "                                                  filters, kernel_size, pool_size, learning_rate)\n",
        "            if val_accuracy is not None:  # Skip incompatible configurations\n",
        "                print(f\"Filters: {filters}, Kernel Size: {kernel_size}, Pool Size: {pool_size}, \"\n",
        "                      f\"Accuracy: {val_accuracy}, Time: {runtime:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM-OZicj9QOS",
        "outputId": "36792519-5941-4532-a247-5a791c34fedb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filters: 32, Kernel Size: 3, Pool Size: 2, Accuracy: 0.7555555701255798, Time: 4.21 seconds\n",
            "Filters: 32, Kernel Size: 3, Pool Size: 3, Accuracy: 0.7511110901832581, Time: 3.41 seconds\n",
            "Filters: 64, Kernel Size: 3, Pool Size: 2, Accuracy: 0.7644444704055786, Time: 6.09 seconds\n",
            "Filters: 64, Kernel Size: 3, Pool Size: 3, Accuracy: 0.7488889098167419, Time: 3.29 seconds\n",
            "Filters: 128, Kernel Size: 3, Pool Size: 2, Accuracy: 0.7611111402511597, Time: 3.75 seconds\n",
            "Filters: 128, Kernel Size: 3, Pool Size: 3, Accuracy: 0.7633333206176758, Time: 6.58 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Constants - adjust these based on your dataset\n",
        "NUM_CLASSES = 6  # Example, change based on your dataset\n",
        "INPUT_SHAPE = (6, 1)  # Assuming 6 features as per your dataset description\n",
        "GENERATIONS = 3\n",
        "POPULATION_SIZE = 6\n",
        "TOURNAMENT_SIZE = 3\n",
        "CROSSOVER_RATE = 0.7\n",
        "MUTATION_RATE = 0.1\n",
        "\n",
        "# One-hot encoding with adjusted parameter\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "# Define the search space for the CNN architecture\n",
        "search_space = {\n",
        "    'num_conv_layers': [1, 2, 3],\n",
        "    'filters': [32, 64],\n",
        "    'kernel_size': [3, 5],\n",
        "    'pool_size': [2],\n",
        "    'activation': ['relu'],\n",
        "    'learning_rate': [0.001],\n",
        "    'dense_units': [128],\n",
        "    'batch_size': [16, 32],\n",
        "    'n_epoch': [10, 20, 30],\n",
        "}\n",
        "\n",
        "# Function to create an individual (CNN architecture configuration)\n",
        "def create_individual(search_space):\n",
        "    individual = {\n",
        "        'num_conv_layers_branch': random.choice(search_space['num_conv_layers']),\n",
        "        'num_conv_layers_third': random.choice(search_space['num_conv_layers']),\n",
        "        'conv_layers_branch': [],\n",
        "        'conv_layers_third': [],\n",
        "        'learning_rate': random.choice(search_space['learning_rate']),\n",
        "        'dense_units': random.choice(search_space['dense_units']),\n",
        "        'batch_size': random.choice(search_space['batch_size']),\n",
        "        'n_epoch': random.choice(search_space['n_epoch']),\n",
        "    }\n",
        "    for _ in range(individual['num_conv_layers_branch']):\n",
        "        individual['conv_layers_branch'].append({\n",
        "            'filters': random.choice(search_space['filters']),\n",
        "            'kernel_size': random.choice(search_space['kernel_size']),\n",
        "            'activation': random.choice(search_space['activation']),\n",
        "        })\n",
        "    for _ in range(individual['num_conv_layers_third']):\n",
        "        individual['conv_layers_third'].append({\n",
        "            'filters': random.choice(search_space['filters']),\n",
        "            'kernel_size': random.choice(search_space['kernel_size']),\n",
        "            'activation': random.choice(search_space['activation']),\n",
        "        })\n",
        "    return individual\n",
        "\n",
        "def create_model(individual):\n",
        "    inputs = Input(shape=INPUT_SHAPE)\n",
        "    x = inputs\n",
        "    for layer_spec in individual['conv_layers_branch']:\n",
        "        x = Conv1D(filters=layer_spec['filters'], kernel_size=layer_spec['kernel_size'],\n",
        "                   activation=layer_spec['activation'], padding='same')(x)\n",
        "        # Check if pooling can be applied without reducing input size below 1\n",
        "        if tf.keras.backend.int_shape(x)[1] > search_space['pool_size'][0]:\n",
        "            x = MaxPooling1D(pool_size=search_space['pool_size'][0])(x)\n",
        "    for layer_spec in individual['conv_layers_third']:\n",
        "        x = Conv1D(filters=layer_spec['filters'], kernel_size=layer_spec['kernel_size'],\n",
        "                   activation=layer_spec['activation'], padding='same')(x)\n",
        "        # Similar check for the third layer sequence\n",
        "        if tf.keras.backend.int_shape(x)[1] > search_space['pool_size'][0]:\n",
        "            x = MaxPooling1D(pool_size=search_space['pool_size'][0])(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=individual['dense_units'], activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=individual['learning_rate']),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Assuming 'data' is your DataFrame with features and labels\n",
        "# Load your dataset here\n",
        "# data = pd.read_csv('path_to_your_dataset.csv')\n",
        "\n",
        "# Prepare your dataset\n",
        "X = data[['Acc x axis', 'Acc y axis', 'Acc z axis', 'Gyr x axis', 'Gyr y axis', 'Gyr z axis']].values\n",
        "y = data['Label'].values.reshape(-1, 1)  # Reshape y to be a 2D array\n",
        "\n",
        "# One-hot encode labels\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# Split the dataset into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "# Reshape data for Conv1D: (num_samples, num_features, 1)\n",
        "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_val_reshaped = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
        "\n",
        "# Function to evaluate the model (remains largely unchanged)\n",
        "# Update the function to use the prepared dataset and the individual evaluation logic\n",
        "def evaluate_model(model, X_train, y_train, X_val, y_val, individual):\n",
        "    history = model.fit(X_train, y_train, epochs=individual['n_epoch'], batch_size=individual['batch_size'], verbose=0, validation_data=(X_val, y_val))\n",
        "    _, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    # Printing the individual's configuration and achieved accuracy\n",
        "    print(\"\\nModel Configuration & Performance:\")\n",
        "    print(f\"Filters in 'conv_layers_branch': {[layer['filters'] for layer in individual['conv_layers_branch']]}\")\n",
        "    print(f\"Filters in 'conv_layers_third': {[layer['filters'] for layer in individual['conv_layers_third']]}\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# Genetic algorithm main logic (remains largely unchanged)\n",
        "# Make sure to adapt any function or logic that needs to consider the dataset specifics or CNN architecture adjustments\n",
        "\n",
        "# Here, you would include the genetic algorithm's main loop, selection, crossover, and mutation functions,\n",
        "# similar to your initial setup but now working with the prepared dataset and the CNN models created based on individuals.\n",
        "# Crossover operation\n",
        "# Enhanced Crossover Operation\n",
        "def crossover(individual1, individual2):\n",
        "    child1, child2 = individual1.copy(), individual2.copy()  # Creating deep copies for crossover\n",
        "    if random.random() < CROSSOVER_RATE:\n",
        "        print(\"\\nCrossover operation:\")\n",
        "        # Example crossover operation: Swap 'conv_layers_branch' configurations\n",
        "        child1['conv_layers_branch'], child2['conv_layers_branch'] = individual2['conv_layers_branch'], individual1['conv_layers_branch']\n",
        "        print(f\"Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\")\n",
        "    else:\n",
        "        print(\"\\nCrossover operation skipped.\")\n",
        "    return child1, child2\n",
        "\n",
        "# Enhanced Mutation Operation\n",
        "def mutate(individual):\n",
        "    mutation_occurred = False\n",
        "    if random.random() < MUTATION_RATE:\n",
        "        # Example mutation operation: Change filters of the first layer in 'conv_layers_branch'\n",
        "        if individual['conv_layers_branch']:\n",
        "            old_value = individual['conv_layers_branch'][0]['filters']\n",
        "            individual['conv_layers_branch'][0]['filters'] = random.choice(search_space['filters'])\n",
        "            print(f\"\\nMutation: 'conv_layers_branch'[0]['filters'] changed from {old_value} to {individual['conv_layers_branch'][0]['filters']}\")\n",
        "            mutation_occurred = True\n",
        "    if not mutation_occurred:\n",
        "        print(\"\\nMutation skipped.\")\n",
        "    return individual\n",
        "\n",
        "\n",
        "# Tournament Selection\n",
        "def tournament_selection(population_with_scores, tournament_size):\n",
        "    tournament = random.sample(population_with_scores, tournament_size)\n",
        "    tournament.sort(key=lambda x: x[1], reverse=True)  # Sort by accuracy in descending order\n",
        "    return tournament[0][0]  # Return the individual with the highest accuracy\n",
        "\n",
        "# Genetic Algorithm Main Loop\n",
        "def genetic_algorithm(X_train, y_train, X_val, y_val, generations, population_size):\n",
        "    population = [create_individual(search_space) for _ in range(population_size)]\n",
        "\n",
        "    for generation in range(generations):\n",
        "        print(f\"Generation {generation + 1}/{generations}\")\n",
        "\n",
        "        # Evaluate Population\n",
        "        population_with_scores = []\n",
        "        for individual in population:\n",
        "            model = create_model(individual)\n",
        "            accuracy = evaluate_model(model, X_train, y_train, X_val, y_val, individual)\n",
        "            population_with_scores.append((individual, accuracy))\n",
        "            print(f\"Individual with {individual['dense_units']} dense units got accuracy: {accuracy}\")\n",
        "\n",
        "        # Selection\n",
        "        selected_individuals = [tournament_selection(population_with_scores, TOURNAMENT_SIZE) for _ in range(population_size)]\n",
        "\n",
        "        # Crossover and Mutation\n",
        "        next_population = []\n",
        "        for i in range(0, population_size, 2):\n",
        "            parent1, parent2 = selected_individuals[i], selected_individuals[i+1]\n",
        "            child1, child2 = crossover(parent1.copy(), parent2.copy())  # Create copies to avoid modifying originals\n",
        "            child1 = mutate(child1)\n",
        "            child2 = mutate(child2)\n",
        "            next_population.extend([child1, child2])\n",
        "\n",
        "        population = next_population\n",
        "\n",
        "    # Find the best individual in the final population\n",
        "    best_individual = max(population_with_scores, key=lambda x: x[1])[0]\n",
        "    best_accuracy = max(population_with_scores, key=lambda x: x[1])[1]\n",
        "    return best_individual, best_accuracy\n",
        "\n",
        "# Running the genetic algorithm\n",
        "best_individual, best_accuracy = genetic_algorithm(X_train_reshaped, y_train, X_val_reshaped, y_val, GENERATIONS, POPULATION_SIZE)\n",
        "\n",
        "print(\"Best Individual Configuration:\", best_individual)\n",
        "print(\"Best Accuracy:\", best_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M22lVQw-EWHT",
        "outputId": "9d7bbbf0-6a0e-4d4a-eef7-b97971b3774c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1/3\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 32, 64]\n",
            "Filters in 'conv_layers_third': [32, 64, 32]\n",
            "Accuracy: 0.757777750492096\n",
            "Individual with 128 dense units got accuracy: 0.757777750492096\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 32]\n",
            "Filters in 'conv_layers_third': [32]\n",
            "Accuracy: 0.7611111402511597\n",
            "Individual with 128 dense units got accuracy: 0.7611111402511597\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [32, 32, 64]\n",
            "Filters in 'conv_layers_third': [32, 32, 64]\n",
            "Accuracy: 0.7666666507720947\n",
            "Individual with 128 dense units got accuracy: 0.7666666507720947\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 32, 32]\n",
            "Filters in 'conv_layers_third': [32, 64]\n",
            "Accuracy: 0.7355555295944214\n",
            "Individual with 128 dense units got accuracy: 0.7355555295944214\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [32, 32, 64]\n",
            "Filters in 'conv_layers_third': [64, 32, 64]\n",
            "Accuracy: 0.6688888669013977\n",
            "Individual with 128 dense units got accuracy: 0.6688888669013977\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 64]\n",
            "Filters in 'conv_layers_third': [64]\n",
            "Accuracy: 0.7644444704055786\n",
            "Individual with 128 dense units got accuracy: 0.7644444704055786\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation: 'conv_layers_branch'[0]['filters'] changed from 32 to 32\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "Generation 2/3\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 32]\n",
            "Filters in 'conv_layers_third': [32, 32, 64]\n",
            "Accuracy: 0.7822222113609314\n",
            "Individual with 128 dense units got accuracy: 0.7822222113609314\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [32, 32, 64]\n",
            "Filters in 'conv_layers_third': [32]\n",
            "Accuracy: 0.7355555295944214\n",
            "Individual with 128 dense units got accuracy: 0.7355555295944214\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 64]\n",
            "Filters in 'conv_layers_third': [32, 32, 64]\n",
            "Accuracy: 0.7777777910232544\n",
            "Individual with 128 dense units got accuracy: 0.7777777910232544\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [32, 32, 64]\n",
            "Filters in 'conv_layers_third': [64]\n",
            "Accuracy: 0.7755555510520935\n",
            "Individual with 128 dense units got accuracy: 0.7755555510520935\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 64]\n",
            "Filters in 'conv_layers_third': [32, 32, 64]\n",
            "Accuracy: 0.7722222208976746\n",
            "Individual with 128 dense units got accuracy: 0.7722222208976746\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [32, 32, 64]\n",
            "Filters in 'conv_layers_third': [64]\n",
            "Accuracy: 0.7766666412353516\n",
            "Individual with 128 dense units got accuracy: 0.7766666412353516\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Crossover operation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "Generation 3/3\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [32, 32, 64]\n",
            "Filters in 'conv_layers_third': [32, 32, 64]\n",
            "Accuracy: 0.7555555701255798\n",
            "Individual with 128 dense units got accuracy: 0.7555555701255798\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 32]\n",
            "Filters in 'conv_layers_third': [64]\n",
            "Accuracy: 0.7722222208976746\n",
            "Individual with 128 dense units got accuracy: 0.7722222208976746\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 64]\n",
            "Filters in 'conv_layers_third': [64]\n",
            "Accuracy: 0.7711111307144165\n",
            "Individual with 128 dense units got accuracy: 0.7711111307144165\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [32, 32, 64]\n",
            "Filters in 'conv_layers_third': [32, 32, 64]\n",
            "Accuracy: 0.7755555510520935\n",
            "Individual with 128 dense units got accuracy: 0.7755555510520935\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 32]\n",
            "Filters in 'conv_layers_third': [32, 32, 64]\n",
            "Accuracy: 0.7744444608688354\n",
            "Individual with 128 dense units got accuracy: 0.7744444608688354\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 32]\n",
            "Filters in 'conv_layers_third': [32, 32, 64]\n",
            "Accuracy: 0.7699999809265137\n",
            "Individual with 128 dense units got accuracy: 0.7699999809265137\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "Best Individual Configuration: {'num_conv_layers_branch': 3, 'num_conv_layers_third': 3, 'conv_layers_branch': [{'filters': 32, 'kernel_size': 3, 'activation': 'relu'}, {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}, {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}], 'conv_layers_third': [{'filters': 32, 'kernel_size': 5, 'activation': 'relu'}, {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}, {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}], 'learning_rate': 0.001, 'dense_units': 128, 'batch_size': 16, 'n_epoch': 30}\n",
            "Best Accuracy: 0.7755555510520935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "NUM_CLASSES = 6\n",
        "INPUT_SHAPE = (6, 1)\n",
        "GENERATIONS = 3\n",
        "POPULATION_SIZE = 6\n",
        "TOURNAMENT_SIZE = 3\n",
        "CROSSOVER_RATE = 0.7\n",
        "MUTATION_RATE = 0.1\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "search_space = {\n",
        "    'num_conv_layers': [1, 2, 3],\n",
        "    'filters': [32, 64],\n",
        "    'kernel_size': [3, 5],\n",
        "    'pool_size': [2],\n",
        "    'activation': ['relu'],\n",
        "    'learning_rate': [0.001],\n",
        "    'dense_units': [128],\n",
        "    'batch_size': [16, 32],\n",
        "    'n_epoch': [10, 20, 30],\n",
        "}\n",
        "\n",
        "# Function to create an individual (CNN architecture configuration)\n",
        "def create_individual(search_space):\n",
        "    individual = {\n",
        "        'num_conv_layers_branch': random.choice(search_space['num_conv_layers']),\n",
        "        'num_conv_layers_third': random.choice(search_space['num_conv_layers']),\n",
        "        'conv_layers_branch': [],\n",
        "        'conv_layers_third': [],\n",
        "        'learning_rate': random.choice(search_space['learning_rate']),\n",
        "        'dense_units': random.choice(search_space['dense_units']),\n",
        "        'batch_size': random.choice(search_space['batch_size']),\n",
        "        'n_epoch': random.choice(search_space['n_epoch']),\n",
        "    }\n",
        "    for _ in range(individual['num_conv_layers_branch']):\n",
        "        individual['conv_layers_branch'].append({\n",
        "            'filters': random.choice(search_space['filters']),\n",
        "            'kernel_size': random.choice(search_space['kernel_size']),\n",
        "            'activation': random.choice(search_space['activation']),\n",
        "        })\n",
        "    for _ in range(individual['num_conv_layers_third']):\n",
        "        individual['conv_layers_third'].append({\n",
        "            'filters': random.choice(search_space['filters']),\n",
        "            'kernel_size': random.choice(search_space['kernel_size']),\n",
        "            'activation': random.choice(search_space['activation']),\n",
        "        })\n",
        "    return individual\n",
        "\n",
        "def create_model(individual):\n",
        "    inputs = Input(shape=INPUT_SHAPE)\n",
        "    x = inputs\n",
        "    for layer_spec in individual['conv_layers_branch']:\n",
        "        x = Conv1D(filters=layer_spec['filters'], kernel_size=layer_spec['kernel_size'],\n",
        "                   activation=layer_spec['activation'], padding='same')(x)\n",
        "        # Check if pooling can be applied without reducing input size below 1\n",
        "        if tf.keras.backend.int_shape(x)[1] > search_space['pool_size'][0]:\n",
        "            x = MaxPooling1D(pool_size=search_space['pool_size'][0])(x)\n",
        "    for layer_spec in individual['conv_layers_third']:\n",
        "        x = Conv1D(filters=layer_spec['filters'], kernel_size=layer_spec['kernel_size'],\n",
        "                   activation=layer_spec['activation'], padding='same')(x)\n",
        "        # Similar check for the third layer sequence\n",
        "        if tf.keras.backend.int_shape(x)[1] > search_space['pool_size'][0]:\n",
        "            x = MaxPooling1D(pool_size=search_space['pool_size'][0])(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=individual['dense_units'], activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=individual['learning_rate']),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "X = data[['Acc x axis', 'Acc y axis', 'Acc z axis', 'Gyr x axis', 'Gyr y axis', 'Gyr z axis']].values\n",
        "y = data['Label'].values.reshape(-1, 1)\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_val_reshaped = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
        "\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, X_val, y_val, individual):\n",
        "    history = model.fit(X_train, y_train, epochs=individual['n_epoch'], batch_size=individual['batch_size'], verbose=0, validation_data=(X_val, y_val))\n",
        "    _, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "    print(\"\\nModel Configuration & Performance:\")\n",
        "    print(f\"Filters in 'conv_layers_branch': {[layer['filters'] for layer in individual['conv_layers_branch']]}\")\n",
        "    print(f\"Filters in 'conv_layers_third': {[layer['filters'] for layer in individual['conv_layers_third']]}\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def crossover(individual1, individual2):\n",
        "    child1, child2 = individual1.copy(), individual2.copy()\n",
        "    if random.random() < CROSSOVER_RATE:\n",
        "        print(\"\\nCrossover operation:\")\n",
        "        child1['conv_layers_branch'], child2['conv_layers_branch'] = individual2['conv_layers_branch'], individual1['conv_layers_branch']\n",
        "        print(f\"Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\")\n",
        "    else:\n",
        "        print(\"\\nCrossover operation skipped.\")\n",
        "    return child1, child2\n",
        "\n",
        "def mutate(individual):\n",
        "    mutation_occurred = False\n",
        "    if random.random() < MUTATION_RATE:\n",
        "        if individual['conv_layers_branch']:\n",
        "            old_value = individual['conv_layers_branch'][0]['filters']\n",
        "            individual['conv_layers_branch'][0]['filters'] = random.choice(search_space['filters'])\n",
        "            print(f\"\\nMutation: 'conv_layers_branch'[0]['filters'] changed from {old_value} to {individual['conv_layers_branch'][0]['filters']}\")\n",
        "            mutation_occurred = True\n",
        "    if not mutation_occurred:\n",
        "        print(\"\\nMutation skipped.\")\n",
        "    return individual\n",
        "\n",
        "def tournament_selection(population_with_scores, tournament_size):\n",
        "    tournament = random.sample(population_with_scores, tournament_size)\n",
        "    tournament.sort(key=lambda x: x[1], reverse=True)\n",
        "    return tournament[0][0]\n",
        "\n",
        "def genetic_algorithm(X_train, y_train, X_val, y_val, generations, population_size):\n",
        "    population = [create_individual(search_space) for _ in range(population_size)]\n",
        "\n",
        "    for generation in range(generations):\n",
        "        print(f\"\\n--- Generation {generation + 1} ---\")\n",
        "        population_with_scores = []\n",
        "        for i, individual in enumerate(population):\n",
        "            print(f\"\\nIndividual {i + 1} Configuration:\")\n",
        "            for key, value in individual.items():\n",
        "                if isinstance(value, list):\n",
        "                    print(f\"{key}:\")\n",
        "                    for item in value:\n",
        "                        print(f\"    {item}\")\n",
        "                else:\n",
        "                    print(f\"{key}: {value}\")\n",
        "            model = create_model(individual)\n",
        "            accuracy = evaluate_model(model, X_train, y_train, X_val, y_val, individual)\n",
        "            population_with_scores.append((individual, accuracy))\n",
        "        selected_individuals = [tournament_selection(population_with_scores, TOURNAMENT_SIZE) for _ in range(population_size)]\n",
        "\n",
        "        next_population = []\n",
        "        for i in range(0, population_size, 2):\n",
        "            parent1, parent2 = selected_individuals[i], selected_individuals[i+1]\n",
        "            child1, child2 = crossover(parent1.copy(), parent2.copy())\n",
        "            next_population.append(mutate(child1))\n",
        "            next_population.append(mutate(child2))\n",
        "\n",
        "        population = next_population\n",
        "\n",
        "    best_individual = max(population_with_scores, key=lambda x: x[1])[0]\n",
        "    best_accuracy = max(population_with_scores, key=lambda x: x[1])[1]\n",
        "    return best_individual, best_accuracy\n",
        "\n",
        "best_individual, best_accuracy = genetic_algorithm(X_train_reshaped, y_train, X_val_reshaped, y_val, GENERATIONS, POPULATION_SIZE)\n",
        "\n",
        "print(\"Best Individual Configuration:\", best_individual)\n",
        "print(\"Best Accuracy:\", best_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3M576QAJFH9t",
        "outputId": "56c506b6-bc5b-481c-8e71-14e4aa93b751"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Generation 1 ---\n",
            "\n",
            "Individual 1 Configuration:\n",
            "num_conv_layers_branch: 3\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "    {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 32\n",
            "n_epoch: 20\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [32, 64, 32]\n",
            "Filters in 'conv_layers_third': [32, 64]\n",
            "Accuracy: 0.7488889098167419\n",
            "\n",
            "Individual 2 Configuration:\n",
            "num_conv_layers_branch: 2\n",
            "num_conv_layers_third: 1\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 16\n",
            "n_epoch: 10\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 64]\n",
            "Filters in 'conv_layers_third': [64]\n",
            "Accuracy: 0.7622222304344177\n",
            "\n",
            "Individual 3 Configuration:\n",
            "num_conv_layers_branch: 2\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 32\n",
            "n_epoch: 20\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [32, 32]\n",
            "Filters in 'conv_layers_third': [32, 32]\n",
            "Accuracy: 0.7677778005599976\n",
            "\n",
            "Individual 4 Configuration:\n",
            "num_conv_layers_branch: 3\n",
            "num_conv_layers_third: 3\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}\n",
            "    {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 32\n",
            "n_epoch: 30\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 64, 32]\n",
            "Filters in 'conv_layers_third': [64, 32, 64]\n",
            "Accuracy: 0.7333333492279053\n",
            "\n",
            "Individual 5 Configuration:\n",
            "num_conv_layers_branch: 1\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 16\n",
            "n_epoch: 30\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64]\n",
            "Filters in 'conv_layers_third': [32, 32]\n",
            "Accuracy: 0.7799999713897705\n",
            "\n",
            "Individual 6 Configuration:\n",
            "num_conv_layers_branch: 2\n",
            "num_conv_layers_third: 3\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 32\n",
            "n_epoch: 30\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 64]\n",
            "Filters in 'conv_layers_third': [32, 32, 64]\n",
            "Accuracy: 0.7688888907432556\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "--- Generation 2 ---\n",
            "\n",
            "Individual 1 Configuration:\n",
            "num_conv_layers_branch: 1\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 16\n",
            "n_epoch: 30\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64]\n",
            "Filters in 'conv_layers_third': [32, 32]\n",
            "Accuracy: 0.7900000214576721\n",
            "\n",
            "Individual 2 Configuration:\n",
            "num_conv_layers_branch: 1\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 16\n",
            "n_epoch: 30\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64]\n",
            "Filters in 'conv_layers_third': [32, 32]\n",
            "Accuracy: 0.7666666507720947\n",
            "\n",
            "Individual 3 Configuration:\n",
            "num_conv_layers_branch: 2\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 32\n",
            "n_epoch: 20\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64]\n",
            "Filters in 'conv_layers_third': [32, 32]\n",
            "Accuracy: 0.7744444608688354\n",
            "\n",
            "Individual 4 Configuration:\n",
            "num_conv_layers_branch: 1\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 16\n",
            "n_epoch: 30\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [32, 32]\n",
            "Filters in 'conv_layers_third': [32, 32]\n",
            "Accuracy: 0.7711111307144165\n",
            "\n",
            "Individual 5 Configuration:\n",
            "num_conv_layers_branch: 1\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 16\n",
            "n_epoch: 30\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64, 64]\n",
            "Filters in 'conv_layers_third': [32, 32]\n",
            "Accuracy: 0.7866666913032532\n",
            "\n",
            "Individual 6 Configuration:\n",
            "num_conv_layers_branch: 2\n",
            "num_conv_layers_third: 3\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 32\n",
            "n_epoch: 30\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64]\n",
            "Filters in 'conv_layers_third': [32, 32, 64]\n",
            "Accuracy: 0.7644444704055786\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Crossover operation:\n",
            "Individual 1 'conv_layers_branch' swapped with Individual 2 'conv_layers_branch'\n",
            "\n",
            "Mutation skipped.\n",
            "\n",
            "Mutation: 'conv_layers_branch'[0]['filters'] changed from 64 to 64\n",
            "\n",
            "--- Generation 3 ---\n",
            "\n",
            "Individual 1 Configuration:\n",
            "num_conv_layers_branch: 2\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 32\n",
            "n_epoch: 20\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64]\n",
            "Filters in 'conv_layers_third': [32, 32]\n",
            "Accuracy: 0.7733333110809326\n",
            "\n",
            "Individual 2 Configuration:\n",
            "num_conv_layers_branch: 1\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 16\n",
            "n_epoch: 30\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64]\n",
            "Filters in 'conv_layers_third': [32, 32]\n",
            "Accuracy: 0.7888888716697693\n",
            "\n",
            "Individual 3 Configuration:\n",
            "num_conv_layers_branch: 1\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 16\n",
            "n_epoch: 30\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64]\n",
            "Filters in 'conv_layers_third': [32, 32]\n",
            "Accuracy: 0.7822222113609314\n",
            "\n",
            "Individual 4 Configuration:\n",
            "num_conv_layers_branch: 1\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 16\n",
            "n_epoch: 30\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64]\n",
            "Filters in 'conv_layers_third': [32, 32]\n",
            "Accuracy: 0.7877777814865112\n",
            "\n",
            "Individual 5 Configuration:\n",
            "num_conv_layers_branch: 1\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 16\n",
            "n_epoch: 30\n",
            "\n",
            "Model Configuration & Performance:\n",
            "Filters in 'conv_layers_branch': [64]\n",
            "Filters in 'conv_layers_third': [32, 32]\n",
            "Accuracy: 0.7922222018241882\n",
            "\n",
            "Individual 6 Configuration:\n",
            "num_conv_layers_branch: 1\n",
            "num_conv_layers_third: 2\n",
            "conv_layers_branch:\n",
            "    {'filters': 64, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 64, 'kernel_size': 3, 'activation': 'relu'}\n",
            "conv_layers_third:\n",
            "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu'}\n",
            "    {'filters': 32, 'kernel_size': 3, 'activation': 'relu'}\n",
            "learning_rate: 0.001\n",
            "dense_units: 128\n",
            "batch_size: 16\n",
            "n_epoch: 30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-084e83236849>\u001b[0m in \u001b[0;36m<cell line: 202>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;31m# Running the genetic algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m \u001b[0mbest_individual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenetic_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGENERATIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPOPULATION_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Individual Configuration:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_individual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-084e83236849>\u001b[0m in \u001b[0;36mgenetic_algorithm\u001b[0;34m(X_train, y_train, X_val, y_val, generations, population_size)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# Create and evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mpopulation_with_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-084e83236849>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, X_train, y_train, X_val, y_val, individual)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m# Update the function to use the prepared dataset and the individual evaluation logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Printing the individual's configuration and achieved accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}